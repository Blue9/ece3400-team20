<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>ECE 3400 Team 20 - Home</title>
    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom fonts for this template -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <!-- Plugin CSS -->
    <link href="vendor/magnific-popup/magnific-popup.css" rel="stylesheet" type="text/css">
    <!-- Custom styles for this template -->
    <link href="css/freelancer.css" rel="stylesheet">
    <link rel="stylesheet" href="css/styles/default.css">
    <script src="js/highlight.pack.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>
</head>

<body id="page-top">
    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg bg-secondary fixed-top text-uppercase" id="mainNav">
        <div class="container">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">ECE 3400</a>
            <button class="navbar-toggler navbar-toggler-right text-uppercase bg-primary text-white rounded" type="button"
                data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false"
                aria-label="Toggle navigation">
                Menu
                <i class="fa fa-bars"></i>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item mx-0 mx-lg-1">
                        <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger active" href="index.html">Labs</a>
                    </li>
                    <li class="nav-item mx-0 mx-lg-1">
                        <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="teamcontract.html">Contract</a>
                    </li>

                    <li class="nav-item mx-0 mx-lg-1">
                        <a class="nav-link py-3 px-0 px-lg-3 rounded js-scroll-trigger" href="https://github.com/Blue9/ece3400-team20">GitHub
                            <i class="fa fa-external-link"></i></a>
                    </li>
                </ul>
            </div>
        </div>
    </nav>
    <!-- Header -->
    <header class="masthead bg-primary text-white text-center">
        <div class="container">
            <img class="img-fluid mb-5 d-block mx-auto" src="img/Circuit_Bear.png" alt="" style="width: 256px; height: 256px;">
            <h1 class="text-uppercase mb-0">The Omega</h1>
            <hr class="star-light">
        </div>

    </header>
    <!-- Portfolio Grid Section -->
    <section class="portfolio" id="portfolio">
        <div class="container">
            <h2 class="text-center text-uppercase text-secondary mb-0">Labs</h2>
            <hr class="star-dark mb-5">
            <div class="row">
                <div class="col-md-6 col-lg-3">
                    <a class="portfolio-item d-block mx-auto" href="#portfolio-modal-1">
                        <div class="portfolio-item-caption d-flex position-absolute h-100 w-100">
                            <div class="portfolio-item-caption-content my-auto w-100 text-center text-white">
                                <h3>Lab 1</h3>
                            </div>
                        </div>
                        <img class="img-fluid" src="img/portfolio/arduino.png" alt="">
                    </a>
                </div>
                <div class="col-md-6 col-lg-3">
                    <a class="portfolio-item d-block mx-auto" href="#portfolio-modal-2">
                        <div class="portfolio-item-caption d-flex position-absolute h-100 w-100">
                            <div class="portfolio-item-caption-content my-auto w-100 text-center text-white">
                                <h3>Lab 2</h3>
                            </div>
                        </div>
                        <img class="img-fluid" src="img/portfolio/Mic_LED.png" alt="">
                    </a>
                </div>
                <div class="col-md-6 col-lg-3">
                    <a class="portfolio-item d-block mx-auto" href="#portfolio-modal-3">
                        <div class="portfolio-item-caption d-flex position-absolute h-100 w-100">
                            <div class="portfolio-item-caption-content my-auto w-100 text-center text-white">
                                <h3>Lab 3</h3>
                            </div>
                        </div>
                        <img class="img-fluid" src="img/portfolio/transmitter.png" alt="">
                    </a>
                </div>
                <div class="col-md-6 col-lg-3">
                    <a class="portfolio-item d-block mx-auto btn disabled" href="#portfolio-modal-4">
                        <div class="portfolio-item-caption d-flex position-absolute h-100 w-100">
                            <div class="portfolio-item-caption-content my-auto w-100 text-center text-white">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img class="img-fluid" src="img/portfolio/arduino.png" alt="">
                    </a>
                </div>
            </div>
            <h2 class="text-center text-uppercase text-secondary mb-0">Milestones</h2>
            <hr class="star-dark mb-5">
            <div class="row">
                <div class="col-md-6 col-lg-3">
                    <a class="portfolio-item d-block mx-auto " href="#portfolio-modal-5">
                        <div class="portfolio-item-caption d-flex position-absolute h-100 w-100">
                            <div class="portfolio-item-caption-content my-auto w-100 text-center text-white">
                                <h3> Milestone 1</h3>
                            </div>
                        </div>
                        <img class="img-fluid" src="img/portfolio/Seven_segment_milestone.png" alt="">
                    </a>
                </div>
                <div class="col-md-6 col-lg-3">
                    <a class="portfolio-item d-block mx-auto " href="#portfolio-modal-6">
                        <div class="portfolio-item-caption d-flex position-absolute h-100 w-100">
                            <div class="portfolio-item-caption-content my-auto w-100 text-center text-white">
                                <h3>Milestone 2</h3>
                            </div>
                        </div>
                        <img class="img-fluid" src="img/portfolio/maze_milestone.png" alt="">
                    </a>
                </div>
                <div class="col-md-6 col-lg-3">
                    <a class="portfolio-item d-block mx-auto btn disabled" href="#portfolio-modal-7">
                        <div class="portfolio-item-caption d-flex position-absolute h-100 w-100">
                            <div class="portfolio-item-caption-content my-auto w-100 text-center text-white">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img class="img-fluid" src="img/portfolio/arduino.png" alt="">
                    </a>
                </div>
                <div class="col-md-6 col-lg-3">
                    <a class="portfolio-item d-block mx-auto btn disabled" href="#portfolio-modal-8">
                        <div class="portfolio-item-caption d-flex position-absolute h-100 w-100">
                            <div class="portfolio-item-caption-content my-auto w-100 text-center text-white">
                                <i class="fa fa-search-plus fa-3x"></i>
                            </div>
                        </div>
                        <img class="img-fluid" src="img/portfolio/arduino.png" alt="">
                    </a>
                </div>
            </div>
        </div>
    </section>
    <!-- About Section
            <section class="bg-primary text-white mb-0" id="about">
            <div class="container">
            <h2 class="text-center text-uppercase text-white">About</h2>
            <hr class="star-light mb-5">
            <div class="row">
            <div class="col-lg-4 ml-auto">
            <p class="lead">Freelancer is a free bootstrap theme created by Start Bootstrap. The download includes the complete source files including HTML, CSS, and JavaScript as well as optional LESS stylesheets for easy customization.</p>
            </div>
            <div class="col-lg-4 mr-auto">
            <p class="lead">Whether you're a student looking to showcase your work, a professional looking to attract clients, or a graphic artist looking to share your projects, this template is the perfect starting point!</p>
            </div>
            </div>
            <div class="text-center mt-4">
            <a class="btn btn-xl btn-outline-light" href="#">
            <i class="fa fa-download mr-2"></i>
            Download Now!
            </a>
            </div>
            </div>
            </section> -->
    <!-- Footer -->
    <footer class="footer text-center">
        <div class="container">
            <div class="row">
                <div class="col-md-4 mb-5 mb-lg-0">
                    <h4 class="text-uppercase mb-4">Location</h4>
                    <p class="lead mb-0">Cornell University
                        <br>Ithaca, NY 14853
                    </p>
                </div>
                <div class="col-md-4 mb-5 mb-lg-0">
                    <h4 class="text-uppercase mb-4">Around the Web</h4>
                    <ul class="list-inline mb-0">
                        <li class="list-inline-item">
                            <a class="btn btn-outline-light btn-social text-center rounded-circle" href="#">
                                <i class="fa fa-fw fa-facebook"></i>
                            </a>
                        </li>
                        <li class="list-inline-item">
                            <a class="btn btn-outline-light btn-social text-center rounded-circle" href="#">
                                <i class="fa fa-fw fa-google-plus"></i>
                            </a>
                        </li>
                        <li class="list-inline-item">
                            <a class="btn btn-outline-light btn-social text-center rounded-circle" href="#">
                                <i class="fa fa-fw fa-twitter"></i>
                            </a>
                        </li>
                        <li class="list-inline-item">
                            <a class="btn btn-outline-light btn-social text-center rounded-circle" href="#">
                                <i class="fa fa-fw fa-linkedin"></i>
                            </a>
                        </li>
                        <li class="list-inline-item">
                            <a class="btn btn-outline-light btn-social text-center rounded-circle" href="#">
                                <i class="fa fa-fw fa-dribbble"></i>
                            </a>
                        </li>
                    </ul>
                </div>
                <div class="col-md-4">
                    <h4 class="text-uppercase mb-4">About Us</h4>
                    <p class="lead mb-0">We are an award-winning ECE 3400 team.</p>
                </div>
            </div>
        </div>
    </footer>
    <div class="copyright py-4 text-center text-white">
        <div class="container">
            <small>Copyright &copy; Team 20 2018</small>
        </div>
    </div>
    <!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
    <div class="scroll-to-top d-lg-none position-fixed ">
        <a class="js-scroll-trigger d-block text-center text-white rounded" href="#page-top">
            <i class="fa fa-chevron-up"></i>
        </a>
    </div>
    <!-- Portfolio Modals -->
    <!-- Portfolio Modal 1 -->
    <div class="portfolio-modal mfp-hide" id="portfolio-modal-1">
        <div class="portfolio-modal-dialog bg-white">
            <a class="close-button d-none d-md-block portfolio-modal-dismiss" href="#">
                <i class="fa fa-3x fa-times"></i>
            </a>
            <div class="container text-center">
                <div class="row">
                    <div class="col-lg-8 mx-auto">
                        <h2 class="text-secondary text-uppercase mb-0">Lab 1</h2>
                        <hr class="star-dark mb-5">
                        <div class="text-left">
                            <p><em>Objective</em>: The objective of this lab was to gain familiarity with the Arduino
                                UNO microcontroller and its IDE.</p>
                            <h3>Lab Procedure</h3>
                            <h4 class="heading">Communicating with the Arduino and the IDE</h4>
                            <p>We first opened the Arduino IDE and clicked under Files/Examples/01.Basic/Blink. In
                                order to make sure the Arduino UNO was properly connected to the IDE, we clicked under
                                Tools/Board/ and selected Arduino/Genuino UNO. We also verified that the IDE is
                                connected to the right port by looking under Tools/Port. It should be as in the
                                following images:</p>
                            <p><img style="max-width:100%; max-height: 400px;" src="https://raw.githubusercontent.com/Blue9/ece3400-team20/gh-pages/Labs/Blink.png?token=ALqGCLBrFr-mOmTYEvBasTaXfWTdYf-xks5blqK1wA%3D%3D"
                                    alt="ArduinoBlinkSketch"></p>
                            <p><img style="max-width:100%; max-height: 400px;" src="https://raw.githubusercontent.com/Blue9/ece3400-team20/gh-pages/Labs/Tools.png?token=ALqGCBe1R2TgNZlNnu1_rmeRQ2tHJ5pvks5blqNVwA%3D%3D"
                                    alt="ArduinoToolsImage"></p>
                            <p>We clicked the check mark to compile the sketch and uploaded it to the Arduino UNO. We
                                obtained the following result:</p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/GjLLtRx1XvA"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            <h4 class="heading">Modifying the Blink Sketch</h4>
                            <p>We modified the Blink sketch to communicate with an external LED powered by Pin 0 in
                                series with a 300 Ohm resistor on the breadboard. We also made sure to connect the
                                ground of the Arduino the ground of the LED. The wiring and operation is shown in the
                                following video and the modification to the code is as follows:</p>
                            <ul>
                                <li>Added <code>#define LED_PIN 0</code> at the top of the sketch</li>
                                <li>Replaced <code>LED_BUILTIN</code> with <code>LED_PIN</code></li>
                            </ul>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/NNcXywDYe_s"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            <h4 class="heading">The Serial Monitor and the Analog Pins</h4>
                            <p>The first goal was to be able to see the output of the potentiometer on the Serial
                                monitor on the Arduino UNO. The potentiometer has three pins and so we connected one
                                end to ground, one end to the 5 Volt output on the Arduino Uno for power, and the
                                middle pin to an Analog Pin on the Arduino for reading. We used A0.</p>
                            <p>For the code, we set up the serial monitor and then used AnalogRead in order to read the
                                input. The code is as follows:</p>
                            <pre><code class="arduino">
<!--                         -->void setup() {
<!--                         -->    Serial.begin(9600); // setting up the Serial monitor
<!--                         -->}

<!--                         -->void loop() {
<!--                         -->    int a = analogRead(A0); // Read the Input
<!--                         -->    Serial.println(a); // Print the output to the serial monitor and create a new line
<!--                         -->}
                            </code></pre>
                            <p>Our result for this part is as follows:</p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/0JiTJ-EnS_w"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            <h4 class="heading">Analog Output</h4>
                            <p>The next goal was to be able to take the potentiometer value and map it to a PWM output
                                that goes to the LED. For reference on PWM, we found the following article helpful: <a
                                    href="https://en.wikipedia.org/wiki/Pulse-width_modulation">https://en.wikipedia.org/wiki/Pulse-width_modulation</a>.</p>
                            <p>We used the wiring from the previous part for the potentiometer and connected an LED in
                                series with a 300 Ohm resistor to digital pin 5 (PWM pin) all with common grounds.
                                <br> Our code for this was as follows:
                            </p>
                            <pre><code>
<!--                         -->#define POT_PIN A0
<!--                         -->#define LED_PIN 5

<!--                         -->// the setup function runs once when you press reset or power the board
<!--                         -->void setup() {
<!--                         -->    Serial.begin(9600);           // initialize the serial monitor
<!--                         -->    pinMode(LED_PIN, OUTPUT);     // setup the LED_PIN as output
<!--                         -->}

<!--                         -->// the loop function runs over and over again forever
<!--                         -->void loop() {
<!--                         -->    int a = analogRead(POT_PIN);  // read from the analog pin
<!--                         -->    analogWrite(LED_PIN, a/4);    // write to the PWM pin - scaling 1024 -&gt; 256
<!--                         -->}
                            </code></pre>
                            <p><em>Note:</em> <code>analogRead()</code> produces values from <code>0</code> to <code>1023</code>,
                                but <code>analogWrite()</code> only accepts values from <code>0</code> to <code>255</code>
                                so the input was scaled down by a factor of four.</p>
                            <p>What we observed was as follows:</p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/IoDwbJaUMtU"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            <h4 class="heading">Parallax Servos</h4>
                            <p>Instead of the output being written to an LED, we now wrote the output to a Parallax
                                Servos. The involved connecting the red wire to the 5 Volt Arduino output, the black
                                wire to ground, and the white wire to a PWM pin (Pin 5). The code for it is similar;
                                however involved now using the Servos.h library. And so we included this library at the
                                top of the sketch and read its documentation for setting up the Servo from the
                                following link: <a href="https://www.arduino.cc/en/Reference/Servo">https://www.arduino.cc/en/Reference/Servo</a>.</p>
                            <p>We used the following setup and code:</p>
                            <pre><code>
<!--                         -->#include &lt;Servo.h&gt;  // include the Servo library
<!--                         -->#define POT_PIN A0
<!--                         -->Servo myServo;  // create servo object to control a servo
<!--                         -->
<!--                         -->void setup() {
<!--                         -->    myServo.attach(9);            // attaches the servo on pin 9 to the servo object
<!--                         -->    Serial.begin(9600);           // initialize the serial monitor
<!--                         -->}
<!--                         -->
<!--                         -->void loop() {
<!--                         -->    int a = analogRead(POT_PIN);  // read from the analog pin
<!--                         -->    a = map(a, 0, 1023, 0, 180);  // scale 1024 to 180
<!--                         -->    myServo.write(a);             // sets the servo speed
<!--                         -->}
                            </code></pre>
                            <p>What we observed is as follows:</p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/YBj1wgy29BY"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            <h4 class="heading">Assembling the Robot</h4>
                            <p>We assembled the robot and wrote code involving writing to the Servos in order to make
                                an S shape. The following video
                                <br> demonstrates our fully autonomous moving robot:
                            </p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/D5O05hFTHSU"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                        </div>
                        <a class="btn btn-primary btn-lg rounded-pill portfolio-modal-dismiss mt-4" href="#">
                            <i class="fa fa-close"></i> Close Project</a>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio Modal 2 -->
    <div class="portfolio-modal mfp-hide" id="portfolio-modal-2">
        <div class="portfolio-modal-dialog bg-white">
            <a class="close-button d-none d-md-block portfolio-modal-dismiss" href="#">
                <i class="fa fa-3x fa-times"></i>
            </a>
            <div class="container text-center">
                <div class="row">
                    <div class="col-lg-8 mx-auto">
                        <h2 class="text-secondary text-uppercase mb-0">Lab 2</h2>
                        <hr class="star-dark mb-5">
                        <div class="text-left">
                            <p><em>Objective</em>: The goal of this lab was to design and implement analog and digital
                                circuitry to detect both optical and audio signals.</p>
                            <h2><a id="Lab_Procedure_4"></a>Lab Procedure</h2>
                            <h3><a id="Setup_6"></a>Setup</h3>
                            <p>The team was split into two groups, one to detect a 660 Hz audio tone that will signify
                                the
                                start of the competition, and one to detect a 6080 Hz infrared signal. Both groups
                                utilized
                                Open Music Labs Arduino FFT library to perform the required signal analysis. More
                                information on Open Music Labs can be found on their website <a href="http://wiki.openmusiclabs.com/wiki/ArduinoFFT">here</a>.</p>
                            <h3><a id="Audio_10"></a>Audio</h3>
                            <p>We started out by designing the amplification and filtering circuit.<br>
                                The fourier transform maps signals in the time domain into its constituent frequencies
                                in
                                the frequency domain. In a signal’s frequency representation, we can analyze the
                                magnitude
                                of various frequencies to see which frequencies are more present than others. Note that
                                the
                                fourier transform can be applied to both continuous and discrete signals. A fourier
                                transform applied to a discrete function is called the discrete fourier transform
                                (DFT). In
                                computer science, one algorithm to calculate the discrete fourier transform in an
                                optimized
                                way is the Fast Fourier Transform (FFT). The FFT samples a signal at varying time steps
                                and
                                then calculates its frequency components. In this lab we used the FFT to detect when a
                                660Hz tone is played.</p>
                            <p>The following formula can be used to calculate the DFT of a signal:</p>
                            <p><img style="max-width:100%; max-height: 400px;" src="https://raw.githubusercontent.com/Blue9/ece3400-team20/gh-pages/img/portfolio/DFT.png"
                                    alt="logo"></p>
                            <p>where x_k is a N-point sequence of complex points and X_k is the DFT vector.</p>
                            <p>We first brainstormed various amplifiers that would achieve a high enough gain to
                                amplify
                                the 660Hz signal. We decided to use an inverting Op Amp cascaded with a low pass
                                filter.</p>
                            <p>In the above schematic, the microphone input signal passes through DC signal blocking
                                capacitor C1, which is then fed into the inverting input of the op amp. The
                                non-inverting
                                input of the op amp is held at a DC bias of Vdd/2 for maximum output voltage swing. The
                                output signal from the op amp is then passed through a low pass filter with pole at
                                600kHz.
                                We did account for the fact that the LPF acts as a load of the Op Amp when we
                                experimented
                                with capacitor and resistor values. A rough calculation shows that the interstage
                                voltage
                                divider is not too significant. The final values we used amplified the signal producing
                                a
                                gain of around 100x and a low pass filter with cutoff frequency 4kHz. The below image
                                shows
                                an oscilloscope reading when a 660Hz tone is played around 10 cm away from the
                                microphone.</p>
                            <p><img style="max-width:100%; max-height: 400px;" src="https://raw.githubusercontent.com/Blue9/ece3400-team20/gh-pages/img/portfolio/Optical_Amplifier.jpg"
                                    alt="Oscilloscope reading"></p>
                            <p>The below image shows a frequency sweep of the operational amplifier. The cutoff
                                frequency
                                is around 4kHz as mentioned above. Note that this does not affect the gain of the 660Hz
                                signal.</p>
                            <p><img style="max-width:100%; max-height: 400px;" src="https://github.com/Blue9/ece3400-team20/blob/gh-pages/img/FilterFrequencySweep.png?raw=true"
                                    alt="Frequency sweep"></p>
                            <p>On the software side, we initially captured the FFT output from the analog circuit using
                                the
                                example code provided by the FFT library from the Open Music Lab: fft_adc_serial.ino.
                                This
                                script captures analog data on Arduino pin A0 using the embedded ADC at a sampling rate
                                of
                                approximately 38kHz. There are 256 samples (bins) per FFT taken, giving a resolution of
                                38,000/256 ≈ 150Hz. This indicates that we should see the 660Hz tone in bin
                                ceiling(660/150) = 5, which is what we observed. We wrote the following MATLAB script
                                to
                                capture the data output on to the serial port:</p>
                            <pre><code>
<!--                         -->% Ensure that COM port is open
<!--                         -->if ~isempty(instrfind)
<!--                         -->    fclose(instrfind);
<!--                         -->    delete(instrfind);
<!--                         -->end
<!--                         -->
<!--                         -->% Clear old data
<!--                         -->clear all
<!--                         -->close all
<!--                         -->
<!--                         -->% Open serial port on COM3
<!--                         -->myserialport = serial('COM3', 'BaudRate', 115200);
<!--                         -->fopen(myserialport);
<!--                         -->
<!--                         -->% Get data for approximately 4 FFTs to ensure that we get a complete one
<!--                         -->n = 1;
<!--                         -->while n &lt;= 512
<!--                         -->    % 'start' signal will generate matching failure warning
<!--                         -->    % Safe to ignore
<!--                         -->    temp = fscanf(myserialport,'%i');
<!--                         -->    if (isscalar(temp) &amp;&amp; isnumeric(temp))
<!--                         -->            y(n) = temp;
<!--                         -->            n = n+1;
<!--                         -->    end
<!--                         -->end
                            </code></pre>
                            <p>Using this code, we recorded the following data:</p>
                            <p>We observed that the 660Hz tone appeared as a strong peak in bin 5 as expected. In
                                addition,
                                tones at 1320Hz and 1960Hz appear in bins 10 and 15 respectively, demonstrating the
                                linearity of the FFT.<br>
                                Since the peak for 660Hz appears in such a low-numbered bin, we discovered that we
                                could
                                use a significantly slower sampling rate to conserve CPU time. The built-in Arduino
                                function AnalogRead is capable of this. It samples at approximately 8930Hz. This gives
                                us a
                                resolution of 8930/256 ≈ 35Hz. Using this method, we expect to see the 660Hz tone in
                                bin
                                ceiling(660/35) = 19. We modified the code as follows:</p>
                            <pre><code>
<!--                         -->#define LOG_OUT 1 // use the log output function
<!--                         -->#define FFT_N 256 // set to 256 point fft
<!--                         -->
<!--                         -->#include &lt;FFT.h&gt; // include the library
<!--                         -->
<!--                         -->void setup() {
<!--                         -->  Serial.begin(115200);
<!--                         -->}
<!--                         -->
<!--                         -->void loop() {
<!--                         -->  while(1) {
<!--                         -->    cli();
<!--                         -->    for (int i = 0; i &lt; 512 ; i +=2) {
<!--                         -->    fft_input[i] = analogRead(A0);
<!--                         -->    fft_input[i+1] = 0;
<!--                         -->    }
<!--                         -->    fft_window(); // window the data for better frequency response
<!--                         -->    fft_reorder(); // reorder the data before doing the fft
<!--                         -->    fft_run(); // process the data in the fft
<!--                         -->    fft_mag_log(); // take the output of the fft
<!--                         -->    sei();
<!--                         -->    for (byte i = 0 ; i &lt; FFT_N/2 ; i++) {
<!--                         -->        Serial.println(fft_log_out[i]); // send out the data
<!--                         -->    }
<!--                         -->  }
<!--                         -->}
                            </code></pre>
                            <p>Using the same MATLAB script, we captured the following data:</p>
                            <p>We noticed that the actual bin numbers corresponding to the peaks for the 660Hz, 1320Hz,
                                and
                                1960Hz test tones were 20, 39, and 57 respectively. Although these bins are not exactly
                                what we expected, they are within a margin of error of a bin, which we found acceptable
                                for
                                an Arduino.</p>
                            <p>In our next step of testing, we applied the 660 Hz signal with background noise. To see
                                if
                                we could discern the signal from the noise, we looked at the FFT and checked if the bin
                                with the 660Hz signal is within a certain intensity of the other signal. Please see the
                                below video for a demonstration:</p>
                            <p>
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/u_h56zHHiHA"
                                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            </p>
                            <h3><a id="Optical_114"></a>Optical</h3>
                            <p>We first set up the photo-transistor circuit as depicted in the lab handout:</p>
                            <p><img style="max-width:100%; max-height: 400px;" src="https://github.com/Blue9/ece3400-team20/blob/gh-pages/img/portfolio/phototransistor.png?raw=true"
                                    alt="Photo-transistor circuit"></p>
                            <p>We connected it to a 5V Power Source and then connected the IR Hat to 9 Volts. To
                                increase
                                the IR sensor’s range of detection, we added a simple inverting op-amp circuit with a
                                gain
                                of about -100 utilizing resistor values of 100,000 and 1,000 Ohms respectively. See the
                                following article for the circuit design we referenced and built: <a href="https://en.wikipedia.org/wiki/Operational_amplifier_applications#Inverting_amplifier">Inverting
                                    Amplifier</a>. This circuit is shown below but we later found that its benefits
                                were
                                minimal for our practical purposes. And so we decided not to use it in our final
                                design.</p>
                            <p><img style="max-width:100%; max-height: 400px;" src="https://github.com/Blue9/ece3400-team20/blob/gh-pages/img/OpAmpCircuitOptical.png?raw=true"
                                    alt="Op-amp circuit"></p>
                            <p>The next thing that we tested was utilizing the FFT library in order to detect a 6080 Hz
                                signal once the Arduino received the signal. We opened the example sketch:
                                “fft_adc_serial”
                                from the Open Music Labs Library and determined whether it was detecting frequencies
                                from
                                the IR Hat. What we noticed is that that the Arduino was printing values between 0 to
                                256
                                onto the Serial Monitor to denote the value of each of the 256 buckets for the Fourier
                                Transform it was computing.</p>
                            <p>Once we made that observation, we changed the sampling rate, according to the
                                calculations
                                done by the Team Alpha report, by setting the ADCSRA register to 0xe4 from the standard
                                fft_adc_serial script. This makes the ADC sample rate to be about 76,800 Hz. This was
                                done
                                since we needed to sample above 36,000 Hz to detect decoys at 18,000 Hz according to
                                the
                                Nyquist condition and this was smallest sample rate above that constraint. We often
                                printed
                                these Fourier transforms to the Serial monitor to see if we were detecting the correct
                                bin/frequency.</p>
                            <p>We then developed a function denoted as <code>isSignalThere</code> to calculate whether
                                the
                                FFT contained a peak at the frequency we desired. This function takes in the target
                                frequency, the sampling rate, and the FFT array as parameters. The width of each bin is
                                the
                                sampling frequency divided by 256, and the function calculates which bin the target
                                frequency is and then checks whether this bin or its adjacent bins contain a value
                                above a
                                threshold, which was determined through empirical tests to be 60.</p>
                            <pre><code>
<!--                         -->boolean isSignalThere(uint8_t fft[], int targetFrequency, long samplingRate) {
<!--                         -->    long bucketLength = samplingRate / 256;
<!--                         -->    uint8_t maxValue = 0;
<!--                         -->
<!--                         -->    uint8_t threshold = 60; 
<!--                         -->    int targetBucket = targetFrequency / bucketLength;
<!--                         -->    byte width = 2;
<!--                         -->    for (byte i = 0; i &lt; width; i++) {
<!--                         -->    if (fft[targetBucket + i] &gt;= threshold || fft[targetBucket - i] &gt;= threshold) {
<!--                         -->        return true;
<!--                         -->    }
<!--                         -->    }
<!--                         -->    return false;
<!--                         -->}
                            </code></pre>
                            <p>Utilizing this function along with the <code>fft_adc_serial</code> example sketch by
                                calling
                                it with the parameters targetFrequency = 6080 and sampling rate = 76,800, we were able
                                to
                                print to the serial monitor whether we were detecting a signal at 6080 Hz. The
                                following
                                video shows how we were able to detect cycling the IR Hat on and off using the Serial
                                plotter from a foot away:</p>
                            <p>
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/_tRcdDt8q-A"
                                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            </p>
                            <p>We then tested the detection with an IR Decoy that was initially set to 12,000 Hz, later
                                set
                                to 18,000 Hz, and natural/flourescent light to make sure only the 6080 Hz tone was
                                detected.</p>
                            <p>The following video shows how we were able to detect the 6080 Hz signal, but not the
                                decoy
                                when it was placed in the way:</p>
                            <p>
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/_UgpGABSOR8?start=17"
                                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            </p>
                            <p>Finally, the IR Hat and decoy were displaced slightly so the IR sensor sensed both
                                signals,
                                but only detected the 6080Hz tone. The FFT of the two signals is below:</p>
                            <p><img style="max-width:100%; max-height: 400px;" src="https://github.com/Blue9/ece3400-team20/blob/gh-pages/img/portfolio/fftpicopticalteam%20(1).jpg?raw=true"
                                    alt="FFT"></p>
                            <h3><a id="Combined_System_162"></a>Combined System</h3>
                            <p>Once each system had been implemented and tested they were combined into a single
                                Arduino
                                sketch, with the optical signal reading from A0, and the acoustic signal being read
                                from
                                A5. The loop for individual system was put into a function, and were then called from a
                                top
                                level loop, as seen below:</p>
                            <pre><code>
<!--                         -->void loop() {
<!--                         -->  while(1) { // reduces jitter
<!--                         -->    bool audio    = audioFFT();
<!--                         -->    bool optical  = opticalFFT();
<!--                         -->    
<!--                         -->    Serial.print(&quot;Optical: &quot;);
<!--                         -->    Serial.print(optical);
<!--                         -->    Serial.print(&quot;\tAudio: &quot;);
<!--                         -->    Serial.println(audio);
<!--                         -->
<!--                         -->  }
<!--                         -->}
                            </code></pre>
                            <p>Simply pasting the two sets of code into functions do not work properly, as they use
                                different sample rates and ADC settings. To combat this issue initialization of the ADC
                                was
                                moved form the <code>setup()</code> function to each of the individual FFT functions.
                                After
                                this change was made the entire system worked properly as shown in the video below:</p>
                            <p>
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/Ro4x0O4s6_g"
                                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            </p>
                        </div>
                        <a class="btn btn-primary btn-lg rounded-pill portfolio-modal-dismiss" href="#">
                            <i class="fa fa-close"></i> Close Project</a>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio Modal 3 -->
    <div class="portfolio-modal mfp-hide" id="portfolio-modal-3">
        <div class="portfolio-modal-dialog bg-white">
            <a class="close-button d-none d-md-block portfolio-modal-dismiss" href="#">
                <i class="fa fa-3x fa-times"></i>
            </a>
            <div class="container text-center">
                <div class="row">
                    <div class="col-lg-8 mx-auto">
                        <h2 class="text-secondary text-center text-uppercase mb-0">Lab 3</h2>
                        <hr class="star-dark mb-5">
                        <div class="text-left">

                        <p><em>Objective</em>: The goal of this lab was to integrate all of the components of previous
                            labs and milestones into a single working system, as well as develop new functionality to
                            transmit maze data between the robot and a base station that will interface with a GUI,
                            displaying the maze.</p>
                        <h3><a id="Setup_4"></a>Setup</h3>
                        <p>The team was split up into two groups, one to work on development of the radio communication
                            and corresponding protocols, and the other to integrate the previous components together.</p>
                        <h3><a id="Radio_8"></a>Radio</h3>
                        <h5><a id="Getting_Started_with_the_Radios_10"></a>Getting Started with the Radios</h5>
                        <p>We started out by connecting the radios to the special green board and then to the 3.3 Volt
                            Power Supply.<br>
                            We then downloaded the RF24 Library off of &quot;<a href="https://github.com/maniacbug/RF24">https://github.com/maniacbug/RF24</a>&quot;.
                            Once we downloaded the ZIP file, we included the library by navigating to the Arduino
                            application and then to “Sketch” -&gt; “Include Library” -&gt; “Add .Zip File”.</p>
                        <p>We then downloaded the “Getting Started” sketch off of the ECE 3400 Github at<br>
                            &quot;<a href="https://github.com/CEI-lab/ece3400-2018/blob/master/docs/Solutions/lab4/GettingStarted/GettingStarted.ino">https://github.com/CEI-lab/ece3400-2018/blob/master/docs/Solutions/lab4/GettingStarted/GettingStarted.ino</a>&quot;.
                            What we immediately noticed is that it would not compile as a result of the “printf”
                            statements. Thus, we replaced each of the “printf” statements with “Serial.println” and we
                            were able to get the code to compile and upload.</p>
                        <p>At first, we had difficulties with transmitting and receiving utilizing the “Getting
                            Started” sketch. Utilizing a Voltmeter,<br>
                            we recognized that there was a short within the radio that was causing issues and so we had
                            to borrow another groups’ radio in order to continue.</p>
                        <p>We then set our pipe values by utilizing the given formula: 2(3D + N) + X where D = 3 and N
                            = 20 represented our lab date and group number. This yielded 58 and 59 which in hexadecimal
                            are 3A And 3B. And so we changed the pipe values to 0x000000003ALL<br>
                            and 0x000000003BLL respectively.</p>
                        <p>This allowed us to get the “Getting Started” sketch to work with an accuracy of
                            approximately 8 feet from each other.</p>
                        <h4><a id="Transmitting_Robot_Information_26"></a>Transmitting Robot Information</h4>
                        <p>At this point, we needed to develop a method of transmitting data about our surroundings and
                            a way of encoding our surroundings. We decided on the following 2 byte system:</p>
                        <table class="table table-striped table-bordered">
                            <thead>
                                <tr>
                                    <th style="text-align:center">Bit</th>
                                    <th>Description</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td style="text-align:center">15-13</td>
                                    <td>X Coordinate</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">12-10</td>
                                    <td>Y Coordinate</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">9</td>
                                    <td>iamhere (robot is here)</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">8</td>
                                    <td>west (whether there is a west wall)</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">7</td>
                                    <td>north (whether there is a north wall)</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">6</td>
                                    <td>east (whether there is a east wall)</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">5</td>
                                    <td>south (whether there is a south wall)</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">4</td>
                                    <td>robot (whether there is a robot)</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">3-1</td>
                                    <td>treasure (which treasure we detected)</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">0</td>
                                    <td>Unused</td>
                                </tr>
                            </tbody>
                        </table>
                        <p>Thus, we created the global variables x_cord, y_cord, iamhere, west, north, east, south, and
                            robot and depending on whether these values were true or not, we encoded an appropriate 2
                            byte value (short) to send. We created the following method “get_msg” to convert these
                            global variables to the encoded message. We also created an enum for treasures that
                            contained “R_C, R_T, R_S, B_C, B_T, B_S, and NaN” that tsure would take on the values of.
                            The method works as follows:</p>
                        <pre><code>unsigned short get_msg(){
  unsigned short t;
  switch (tsure){
    case R_C : t = 0b110; break;
    case R_T : t = 0b101; break;
    case R_S : t = 0b100; break;
    case B_C : t = 0b011; break;
    case B_T : t = 0b010; break;
    case B_S : t = 0b001; break;
    case NaN : t = 0b000; break; }
    
  unsigned short msg = (x_coord &lt;&lt; 13) + (y_coord &lt;&lt; 10) +
              (iamhere  &lt;&lt; 9) +
              (west     &lt;&lt; 8) +
              (north    &lt;&lt; 7) +
              (east     &lt;&lt; 6) +
              (south    &lt;&lt; 5) +
              (robot    &lt;&lt; 4) +
              (t        &lt;&lt; 1);

  return t;
}

</code></pre>
                        <p>This allowed us to encode messages to write to our radios that would be able to transmit to
                            each other radio.</p>
                        <h4><a id="Receiving_Information_73"></a>Receiving Information:</h4>
                        <p>Once a radio received a packet in the data scheme above, we decoded the information
                            utilizing bit shifting.<br>
                            For example, in order to obtain the x and y coordinates, we used the following masks and
                            bit shifting to decode the values:</p>
                        <pre><code>#define x_mask 0xe000
#define x_shift 13
#define y_mask 0x1c00
#define y_shift 10
#define get_x(a) (a&amp;x_mask) &gt;&gt; x_shift
#define get_y(a) (a&amp;y_mask) &gt;&gt; y_shift
</code></pre>
                        <p>This allowed us to communicate information from one radio to another and decode it
                            appropriately. The following images demonstrates the output when we sent encoded
                            information from one radio to another:</p>

                        <img src="https://github.com/Blue9/ece3400-team20/blob/gh-pages/img/IMG_5380.jpg?raw=true"
                            style="width:500px">
                        <br>
                        <img src="https://github.com/Blue9/ece3400-team20/blob/gh-pages/img/IMG_5381.jpg?raw=true"
                            style="width:500px; margin: 10px auto;">
                        <br>
                        <h4><a id="Updating_GUI_from_the_base_station_92"></a>Updating GUI from the base station</h4>
                        <p>To update the GUI from the base station we first figured out which port the Arduino was
                            connected to as well as the name of the tty shell the serial monitor writes to. We then
                            hardcoded values representing a virtual maze and ran the program. We monitored the GUI to
                            see updates. As expected, the GUI updated to reflect the explored maze.</p>
                        <h4><a id="Interfacing_with_the_GUI_and_Wireless_Communication_97"></a>Interfacing with the GUI
                            and Wireless Communication</h4>
                        <p>Once we were able to send maze information from one Arduino to another, we needed to
                            interface with the GUI. This<br>
                            involved taking the parsed information and turning the information into a formatted string
                            that the GUI would accept to the serial monitor. An example of a string is as follows:
                            “2,3,west=false,north=true,south=false,robot=true.” We were able to generate this string by
                            utilizing tertiary conditionals i.e. if the west bit is 1 then add “true” to the output
                            string and if it is 0 then add “false”.</p>
                        <p>And so once we generated this string from the parsed information, we were able to generate
                            images on the GUI. In order to create a virtual simulation, we created an array of virtual
                            information that the transmitter would iterate through, the receiver would parse and update
                            the GUI with. We manually created this array. The simulation array we used was the
                            following based on the transmission scheme decoded above:</p>
                        <pre><code>{0b0000001110100000, 0b0000011010100000, 0b0000101011000110, 0b0010101001100000, 0b0010011010101010, 0b0010001110000000, 0b0100001100100000, 0b0100011010100000, 0b0100101010100000};
</code></pre>
                        <p>A wireless virtual transmission with an interface with the GUI is presented below. There is
                            slight lagging mostly due to the browser’s refreshing rate.</p>
                        <p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/IlqivRq3zKw"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                        </p>
                        <h4><a id="Efficient_data_scheme_to_store_all_maze_information_on_an_Arduino_112"></a>Efficient
                            data scheme to store all maze information on an Arduino</h4>
                        <p>We used an 8x8 array to store maze information. Each index corresponds to an intersection.
                            To keep the data at a minimum, we stored a two byte short in each index of the array. Each
                            packet sent wirelessly is decoded and stored in the array.Below is an outline of each bit:</p>
                        <h3><a id="Robot_117"></a>Robot</h3>
                        <h4><a id="Audio_FFT_119"></a>Audio FFT</h4>
                        <p>To begin we incorporated the analog audio circuit from Lab 2 onto the primary breadboard,
                            and connecting it to one of the analog input pins. For more information on how the audio
                            circuit is implemented please see ** Lab 2 **.</p>
                        <p>An additional state in our FSM was created as the initial state which waits, continuously
                            checking the <code>audioFFT()</code>, also described in Lab 2, looking for the 660Hz start
                            signal. Upon detecting the signal, the FSM transitions to moving forward and begins
                            traversing the maze via the right hand rule.</p>
                        <p>Once this state was implemented we noticed that the servos jittered in the initial state
                            when <code>audioFFT()</code> was run. After some testing we discovered this was because the
                            <code>audioFFT()</code> function disables the timers and interrupts used by the <code>Servo</code>
                            class.<br>
                            The following changes resolved this issue:</p>
                        <pre><code>// cli(); // &lt;- commented out
...
// sei(); // &lt;- commented out
</code></pre>
                        <p>After this change was made the latency of the <code>audioFFT()</code> was drastically
                            reduced so we had to increase our threshold for the number of sequential FFTs required to
                            detect the start tone from 5 to 15. This ensure that common speech or music did not set off
                            the robot.<br>
                            Below is a video of the robot starting on a tone:</p>
                        <p>Robot starting on a 660Hz tone</p>
                        <p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/J3oYayUAUiY"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                        </p>
                        <p>In case the start tone detection fails, we also incorporated a manual override switch that
                            can start the robot during the competition.<br>
                            Below is a video of the robot starting via manual override:</p>
                        <p>Robot starting from manual override switch:</p>
                        <p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/3r8BT0jyPSM"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                        </p>
                        <h4><a id="Left_Wall_Sensor_147"></a>Left Wall Sensor</h4>
                        <p>Previously, we used two sensors to detect walls: one for detecting walls ahead and one for
                            detecting walls to the right. We left out a left-wall sensor because we did not have enough
                            analog pins, and left wall detection only mattered in the case of a dead-end, in which case
                            our robot would begin to turn, detect the wall on the left (near the end of the turn), and
                            “undo” the turn by reversing out. In this lab, since mapping the walls is needed, we
                            decided to add a left-wall sensor by muxing our wall sensor inputs. After building the
                            necessary circuitry for the mux, we built a few methods for retrieving the various wall
                            sensor values. A code snippet is included below.</p>
                        <pre><code>int sensor_at_wall(int mux_control, int threshold) {
  digitalWrite(MUX_PIN_0, mux_control &amp; 0b01);
  digitalWrite(MUX_PIN_1, (mux_control &amp; 0b10) &gt;&gt; 1);
  return analogRead(WALL_MUX_PIN_IN) &gt; threshold;
}
</code></pre>
                        <p><code>MUX_PIN_0</code> is the LSB of the mux control signal and <code>MUX_PIN_1</code> is
                            the MSB. Since we had already abstracted away the hardware implementation of the wall
                            sensors in methods, we had to make minimal changes to our code to account for this change.</p>
                        <p><em>Note:</em> The mux used was the <a href="http://www.ti.com/lit/ds/symlink/cd74hc4051.pdf">TI
                                CD74HCT4051</a> with the S2 select grounded, making it effectively a 4:1 mux.</p>
                        <h4><a id="Maze_Mapping_162"></a>Maze Mapping</h4>
                        <p>The robot will eventually need to plan its path around the maze using a more substantial
                            algorithm than right-hand wall following. To do this, it will need information about the
                            maze as a whole stored locally on the Arduino. Since there are 64 total intersections, this
                            information must be stored as efficiently as possible.<br>
                            To this end, we designed a new encoding scheme to record information about the walls and
                            treasures located at each intersection. All of this information can be stored in two bytes
                            per intersection as follows:</p>
                        <table class="table table-striped table-bordered">
                            <thead>
                                <tr>
                                    <th style="text-align:center">Bit</th>
                                    <th>Description</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td style="text-align:center">15-11</td>
                                    <td>Unused</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">10-9</td>
                                    <td>Treasure Shape</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">8</td>
                                    <td>West Valid</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">7</td>
                                    <td>West</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">6</td>
                                    <td>North Valid</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">5</td>
                                    <td>North</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">4</td>
                                    <td>East Valid</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">3</td>
                                    <td>East</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">2</td>
                                    <td>South Valid</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">1</td>
                                    <td>South</td>
                                </tr>
                                <tr>
                                    <td style="text-align:center">0</td>
                                    <td>Unused</td>
                                </tr>
                            </tbody>
                        </table>
                        <p>The valid bits allow us to record information about walls at intersections that we have not
                            explored yet. For example, assuming 0,0 is the northwest intersection, if we find a
                            northern wall at intersection 2,3, we know that there is a southern wall at 2,2. In this
                            case, we would set the south bit and the south valid bit of the 2,2 intersection, but the
                            other walls would remain invalid. That way, the robot can reason with the maximum amount of
                            data available. We do not believe that the redundancy is a significant problem, as this
                            only adds a few extra bytes of information total. The data structure as a whole only
                            occupies 128 bytes, so it should not significantly affect our memory usage. Updating this
                            data structure only involves a single call to the array_update function per intersection,
                            so it shouldn’t be a significant drain on processing power either.</p>
                        <h4><a id="Testing_With_Other_Robots_183"></a>Testing With Other Robots</h4>
                        <p>From milestone 2, we were able to test our IR hat and optical FFT implementation. In this
                            lab, we mounted the IR hat at a 5.5 inch height and connected a 9 V source to it. To make sure our
                            robot could avoid other robots, we placed another team's robot in the maze and made sure our robot
                            avoided it. Additionally, we made sure to disable front wall detection while conducting this test
                            to make sure the robot was actually detecting the other robot and not just a wall. A video of this
                            is shown below.
                            
                            <p>
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/9wIbhgJp84U"
                                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            </p>
                            
                            <p>Regarding decoys, we do not actively seek out decoys and ignore them. This is because our
                            optical FFT functions are accurate enough to only return true when an actual robot is
                            detected.
                            </p>
                            
                        <h3><a id="Complete_Integration_186"></a>Complete Integration</h3>
                        <p>After all of the aforementioned changes had be integrated into the design we did a final
                            test of the robot starting on a tone, navigating a maze, storing the maze locally, and
                            transmitting the maze information wirelessly to the base station which interfaced with the
                            GUI. Below is a video of this in action:</p>
                        <p>
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/a42s1vxHHX8"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                        </p>

                        </div>
                        <a class="btn btn-primary btn-lg rounded-pill portfolio-modal-dismiss" href="#">
                            <i class="fa fa-close"></i> Close Project</a>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio Modal 4 -->
    <div class="portfolio-modal mfp-hide" id="portfolio-modal-4">
        <div class="portfolio-modal-dialog bg-white">
            <a class="close-button d-none d-md-block portfolio-modal-dismiss" href="#">
                <i class="fa fa-3x fa-times"></i>
            </a>
            <div class="container text-center">
                <div class="row">
                    <div class="col-lg-8 mx-auto">
                        <h2 class="text-secondary text-uppercase mb-0">Lab 4</h2>
                        <hr class="star-dark mb-5">
                        <img class="img-fluid mb-5" src="img/portfolio/game.png" alt="">
                        <p class="mb-5">Lorem ipsum dolor sit amet, consectetur adipisicing elit. Mollitia neque
                            assumenda ipsam nihil, molestias magnam, recusandae quos quis inventore quisquam velit
                            asperiores, vitae? Reprehenderit soluta, eos quod consequuntur itaque. Nam.</p>
                        <a class="btn btn-primary btn-lg rounded-pill portfolio-modal-dismiss" href="#">
                            <i class="fa fa-close"></i> Close Project</a>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio Modal 5 -->
    <div class="portfolio-modal mfp-hide" id="portfolio-modal-5">
        <div class="portfolio-modal-dialog bg-white">
            <a class="close-button d-none d-md-block portfolio-modal-dismiss" href="#">
                <i class="fa fa-3x fa-times"></i>
            </a>
            <div class="container text-center">
                <div class="row">
                    <div class="col-lg-8 mx-auto">
                        <h2 class="text-secondary text-uppercase mb-0">Milestone 1</h2>
                        <hr class="star-dark mb-5">
                        <div class="text-left">
                            <iframe width="560" height="315" src="https://www.youtube.com/embed/Rsmbcb27Gc8"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
                            <p><strong><em>Lab Procedure:</em></strong></p>
                            <p><em>Objective:</em> The objective of this milestone is to be able to add sensors to the
                                robot as well as program the robot such that the robot will be able to line follow and
                                turn along a grid in a figure eight fashion.</p>
                            <p>The first challenge was being able to determine the placement of the line sensors to
                                optimize line following and turning, knowing whether we are following a line or have
                                reached an intersection. We decided to use two infrared sensors with spacing slightly
                                greater than the tape’s width placed in front of the robot approximately 5 mm above the
                                floor. This placement was chosen so that when the robot detects an intersection both
                                line sensors would read white and while the robot is going straight along a path, both
                                line sensors would read black. If any of the line sensors read white exclusively, i.e.
                                the left sensor reads white and the right sensor reads black or vice-versa, we know
                                that the robot is angled against the line and should adjust accordingly. This
                                adjustment forms the basis for our line-following procedure. We then calibrated the
                                threshold value of each sensor by reading the value on the analog pins along lighter
                                and darker regions of the grid and averaged accordingly.</p>
                            <p><strong><em>Loop Iteration States:</em></strong></p>
                            <p>To implement line following and turning, on each loop iteration, we checked the value of
                                the line sensors with respect to the threshold and classified/adjusted according to the
                                following four states:</p>
                            <p><strong>Left on Right off</strong>: If the left sensor reads white and the right sensor
                                reads black, then we know that the robot is angled against the line, i.e. it has turned
                                too far to the right while line following. As a result, we adjust accordingly by
                                stopping the right wheel (turn left) until both line sensors detect black. We then
                                continue both wheels full speed ahead from there. The following code demonstrates what
                                would happen if this conditional is met:</p>
                            <pre><code>
<!--                         -->adjust_right(0);
<!--                         -->while (sensor_on_white(RIGHT_COLOR_PIN) && !sensor_on_white(LEFT_COLOR_PIN)) {
<!--                         -->    // Wait until neither on white.
<!--                         -->}
<!--                         -->adjust_right(MAX_SPEED);
                            </code></pre>
                            <p><strong>Left off right on</strong>: If the right sensor reads white and the right sensor
                                reads black, then we know that the robot is angled against the line in the other
                                direction, i.e. it has turned too far to the left while line following. As a result, we
                                adjust accordingly by stopping the left wheel (turn right) until both line sensors
                                detect black. We then continue both wheels full speed ahead from there. The following
                                code demonstrates what would happen if this conditional is met:</p>
                            <pre><code>adjust_left(0);
<!--                         -->while (sensor_on_white(LEFT_COLOR_PIN) && !sensor_on_white(RIGHT_COLOR_PIN)) {
<!--                         -->    // Wait until neither on white.
<!--                         -->}
<!--                         -->adjust_left(MAX_SPEED);
<!--                         --></code></pre>
                            <p><strong>Both On</strong>: Based off of the sensor alignment we chose, as aforementioned,
                                if both sensors are on, we must be at an intersection. In order to complete a figure
                                eight in the configuration we chose, the robot must turn left four times and then turn
                                right four times. We kept a variable that kept track of which turn number we are on and
                                used the mod function to decide whether to turn left or right. For example, if the
                                counter variable records the 9th turn, the robot must be at an equivalent position as
                                for the 1st turn (9 % 8 = 1) and turn left. Once we determined which way to turn, we
                                called our turning functions accordingly. The following code demonstrates what would
                                happen if this conditional is met:</p>
                            <pre><code>
<!--                         -->// If both the right and left sensors are on white,
<!--                         -->// then we are at an intersection.
<!--                         -->if (figure_eight_step % 8 &gt; 3) {
<!--                         -->    Serial.println(&quot;Turning left&quot;);
<!--                         -->    turn_left();
<!--                         -->} else {
<!--                         -->    Serial.println(&quot;Turning right&quot;);
<!--                         -->    turn_right();
<!--                         -->}
<!--                         -->figure_eight_step = (figure_eight_step + 1) % 8;
                            </code></pre>
                            <p><strong>Both off</strong>: If both sensors are off, then the robot is aligned with the
                                tape. In this case, we continue forward and have both wheels go at their full speeds.
                                The following code demonstrates what would happen if this conditional is met:</p>
                            <pre><code>
<!--                         -->// Move straight.
<!--                         -->adjust_left(MAX_SPEED);
<!--                         -->adjust_right(MAX_SPEED);
                            </code></pre>
                            <p><strong>Turning Procedures</strong></p>
                            <p>As aforementioned, since the sensors are slightly farther apart then the line is wide,
                                when both sensors detect a line, we know that an intersection has been found. We
                                developed functions to turn in each direction: turn_left() and turn_right(). The
                                function turn_left() stops the left wheel, sets the right wheel to full speed, delays
                                for 900 msec, and restarts the left wheel. The function turn_right() does the same with
                                the wheels switched. We arrived on the timing of 900 msec through rigorous testing. If
                                the turn is not exact, our line following procedure will ensure the robot returns to
                                being centered on the line for increased robustness.</p>
                            <pre><code>
<!--                         -->/**
<!--                         --> * Turn the robot left 90 degrees by slowing down the left servo.
<!--                         --> */
<!--                         -->void turn_left() {
<!--                         -->    adjust_left(0);
<!--                         -->    adjust_right(1);
<!--                         -->    delay(900);
<!--                         -->    adjust_left(1);
<!--                         -->}
<!--                         -->/**
<!--                         --> * Turn the robot right 90 degrees by slowing down the right servo.
<!--                         --> */
<!--                         -->void turn_right() {
<!--                         -->    adjust_left(1);
<!--                         -->    adjust_right(0);
<!--                         -->    delay(900);
<!--                         -->    adjust_right(1);
<!--                         -->}
                            </code></pre>
                            <p><strong>Adjust Functions:</strong></p>
                            <p>In order to reduce the confusion that results from writing values on the servos from 0
                                to 180 where 0 refers to full speed ahead on one wheel and 0 refers to full speed
                                backwards on the other, we developed adjust_left and adjust_right functions that take
                                in values from -1 to 1 that map to the corresponding servos values. For example,
                                adjust_left(0) and adjust_right(0) both refer to stopping, adjust_left(1) and
                                adjust_right(1) refer to full speed ahead, and adjust_left(-1) and adjust_right(-1)
                                refer to full speed backwards. These functions rely on a map function we wrote that
                                utilizes the Servos range of 0 to 180 as the out_min and out_max for the left wheel,
                                and 180 to 0 as the out_min and out_max for the right wheel.</p>
                            <pre><code>
<!--                         -->/**
<!--                         --> * Scale the given value to a new range.
<!--                         --> * @param value_to_map The value to scale.
<!--                         --> * @param in_min The lower bound of the original range.
<!--                         --> * @param in_max The upper bound of the original range.
<!--                         --> * @param out_min The lower bound of the new range.
<!--                         --> * @param out_max The upper bound of the new range.
<!--                         --> * @return The scaled value.
<!--                         --> */
<!--                         -->double map(double value_to_map, double in_min, double in_max, double out_min, double out_max) {
<!--                         -->    return (value_to_map - in_min) * (out_max - out_min) / (in_max - in_min) + out_min;
<!--                         -->}
                            </code></pre>
                        </div>
                        <a class="btn btn-primary btn-lg rounded-pill portfolio-modal-dismiss" href="#">
                            <i class="fa fa-close"></i> Close Project</a>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Portfolio Modal 6 -->
    <div class="portfolio-modal mfp-hide" id="portfolio-modal-6">
        <div class="portfolio-modal-dialog bg-white">
            <a class="close-button d-none d-md-block portfolio-modal-dismiss" href="#">
                <i class="fa fa-3x fa-times"></i>
            </a>
            <div class="container text-left">
                <div class="row">
                    <div class="col-lg-8 mx-auto">
                        <h2 class="text-secondary text-center text-uppercase mb-0">Milestone 2</h2>
                        <h3 class="text-center"><a id="Maze_exploration_using_Right_Hand_Rule_2"></a>Maze exploration
                            using Right Hand Rule</h3>
                        <p>To add maze exploration functionality using the right hand rule, we incorporated the
                            following logic:</p>
                        <pre><code>
<!--                 -->if no_right_wall:
<!--                 -->      turn_right()
<!--                 -->  else if no_front_wall: // right wall is detected but no front wall is detected
<!--                 -->      go_straight()
<!--                 -->  else:
<!--                 -->      turn_left() // right wall and front wall is detected 
<!--                 --></code></pre>
                        <p>We try to turn right at every intersection, and if the right side is blocked, we try moving
                            forward. We added two short distance sensors for wall detection on the right and front of
                            the robot in addition to the IR sensor explored in Lab 2. We also added two indicator LEDs
                            to show whether the robot detects a front or right wall. Front and right wall detection
                            uses an experimentally determined threshold value from the distance sensors. We found 100
                            to be a good threshold for the front wall sensor and 200 to be a good threshold for the
                            right sensor. In case the robot reaches a dead end, the robot will initially start turning
                            left (evaluate the else statement) and detect that there is a wall in front of it. It will
                            then reverse the turn and turn 180 degrees to continue to maze.</p>
                        <p>Due to the extra amount of complexity that arose from wall detection and in order to make
                            our line following system more robust, we incorporated a finite state machine design for
                            navigation. We start our robot in a “move forward” state that iteratively checks our left
                            and right line sensors. If any of those sensors detect that we are no longer line
                            following, then we branch into their respective states to adjust accordingly. If any of the
                            adjusting or “move forward” states also detect that we are at an intersection, by checking
                            if both the left and right sensors are on white, and need to turn according to the right
                            hand rule logic above, we branch into a state that moves the robot slightly past the
                            intersection (forward_until_past_intersection) and sets the turn diction by setting a
                            variable called turn_direction. If we do need to turn, we branch into a state that performs
                            the turn based on the turn_direction (start_turn), determine that the turn is completed
                            (wait_until_turn_completed) based on the line sensors, and then branches back into the
                            “move forward” state and continue our maze detection.</p>
                        <p>Excerpts from the code are as follows. The “only_left_on_white” and “only_right_on_white”
                            function check if only one of the line sensors is on white based on empirical thresholds
                            from the previous lab. We also created “left_on_white” and “right_on_white” to check if the
                            respective sensor is on white. The “both_on_white” function checks if both the line sensors
                            are on white. The “turn_status[turn_direction]” returns “left_on_white” for a left turn and
                            “right_on_white” for a right turn as we start turning left when the left line sensor is no
                            longer on white and turn right when the right line sensor is no longer on white.</p>
                        <!--                 -->
                        <pre><code>int move_forward() {
<!--                 -->  Serial.println(&quot;move forward&quot;);
<!--                 -->  front_led_off(); // initialize the leds to not detect a wall
<!--                 -->  right_led_off();
<!--                 -->  set_left(1); // move the robot forward
<!--                 -->  set_right(1);
<!--                 -->  if (only_left_on_white()) return ADJUST_LEFT; // branch into adjust left state
<!--                 -->  if (only_right_on_white()) return ADJUST_RIGHT; // branch into adjust right state 
<!--                 -->  if (both_on_white() &amp;&amp; (front_wall() || !right_wall() || opticalFFT())) {
<!--                 -->  // check if we are at an intersection and if there is a front wall, no right wall, or a decoy robot
<!--                 -->  // in which case we need to turn
<!--                 -->    return FORWARD_UNTIL_PAST_INTERSECTION; // at an intersection and need to turn
<!--                 -->  }
<!--                 -->  return MOVE_FORWARD;
<!--                 -->}
<!--                 -->
<!--                 -->int forward_until_past_intersection() { // must turn after this state
<!--                 -->  Serial.println(&quot;forward_until_past_intersection&quot;);
<!--                 -->  set_left(1); // move forward
<!--                 -->  set_right(1);
<!--                 -->  if (both_on_white()) return FORWARD_UNTIL_PAST_INTERSECTION; // move a little past the intersection
<!--                 -->  if (!right_wall()) turn_direction = 1; // turn right if no right wall
<!--                 -->  else turn_direction = 0; // else turn left
<!--                 -->  if (!turn_status[turn_direction]()) {
<!--                 -->    // turn_status[turn_direction() checks if left or right line sensor is on white
<!--                 -->    // and so we turn when the respective sensor is past the intersection. We stop, delay, and turn.
<!--                 -->    set_left(0); 
<!--                 -->    set_right(0);
<!--                 -->    delay(10);
<!--                 -->    return START_TURN;
<!--                 -->  }
<!--                 -->  return FORWARD_UNTIL_PAST_INTERSECTION;
<!--                 -->}
<!--                 -->
<!--                 -->int start_turn() {
<!--                 -->  Serial.println(&quot;start turn&quot;);
<!--                 -->  set_left(turn_direction); // set the left and white wheels based on the turn direction
<!--                 -->  set_right(1 - turn_direction); 
<!--                 -->  if (!turn_status[turn_direction]()) return START_TURN;
<!--                 -->  if (turn_status[turn_direction]()) {
<!--                 -->    // if we have seen the respective sensor on white thus halfway done with turn
<!--                 -->    // But before completing turn, check for a dead end.
<!--                 -->    Serial.println(front_wall());
<!--                 -->    if (front_wall() &amp;&amp; turn_direction == 0) return UNDO_TURN;
<!--                 -->    else return WAIT_UNTIL_TURN_END;
<!--                 -->  }
<!--                 -->  return START_TURN;
<!--                 -->}
<!--                 -->
<!--                 -->int wait_until_turn_end() {
<!--                 -->  Serial.println(&quot;wait_until_turn_end&quot;);
<!--                 -->  set_left(turn_direction); 
<!--                 -->  set_right(1 - turn_direction);
<!--                 -->  // turn_status[turn_direction] checks if either the left or right line sensor is on white.
<!--                 -->  // we continue turning until respective sensor is no longer on white line
<!--                 -->  if (turn_status[turn_direction]()) return WAIT_UNTIL_TURN_END;
<!--                 -->  if (!turn_status[turn_direction]()) return MOVE_FORWARD;
<!--                 -->  return WAIT_UNTIL_TURN_END;
<!--                 -->}
<!--                 -->
<!--                 -->
<!--                 --></code></pre>
                        <!--                 -->
                        <p>Once we developed these states and branching conditions, wall-detection worked. The
                            following video demonstrates how our robot is able to detect walls and line follows. Note
                            the flashing LEDs.</p>
                        <h1><iframe width="560" height="315" src="https://www.youtube.com/embed/sdR-A3kpq3s"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></h1>
                        <h3><a id="Avoiding_other_Robots_88"></a>Avoiding other Robots</h3>
                        <p>In order to avoid other robots, we attached an IR Sensor to the front of the robot. The
                            robot performs an FFT utilizing the “optical_FFT” function written in Lab 2. If we do
                            detect a decoy robot, then we treat it as a wall in our wall detection algorithm above.
                            This is why we added an OR statement with “optical_FFT()” above in the “move_forward” state
                            as well as added similar conditions in the “adjust_left” and “adjust_right” states. We
                            initially had issues with integrating the FFT but we adjusted our value of ADCSRA and we
                            found it to work.</p>
                        <p>A video of our robot avoiding other robots, walls, and line following is as follows:</p>
                        <h1><iframe width="560" height="315" src="https://www.youtube.com/embed/XYCFWvGQjow"
                                frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></h1>
                    </div>
                </div>
            </div>
        </div>
    </div>
    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
    <!-- Plugin JavaScript -->
    <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
    <script src="vendor/magnific-popup/jquery.magnific-popup.min.js"></script>
    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>
    <!-- Custom scripts for this template -->
    <script src="js/freelancer.min.js"></script>
</body>

</html>
